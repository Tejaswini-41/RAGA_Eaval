
--- Similar PR #2026 ---
File: docs/howtos/integrations/amazon_bedrock.md
Before:
# Convert Amazon Bedrock traces to messages accepted by RAGAS.
# into a format that RAGAS can process as conversation messages.
# MultiTurnSample is a data type defined in RAGAS that encapsulates conversation


Corrected Snippet:

After:
# Convert Amazon Bedrock traces to messages accepted by Ragas.
# into a format that Ragas can process as conversation messages.
# MultiTurnSample is a data type defined in Ragas that encapsulates conversation

File: docs/howtos/integrations/index.md
Before:
- [LlamaIndex](./_llamaindex.md) - LlamaIndex is a framework for building RAG applications, more information can be found [here](https://www.llamaindex.ai/).
After:
- [LlamaIndex for RAG](./_llamaindex.md) - LlamaIndex is a framework for building RAG applications, more information can be found [here](https://www.llamaindex.ai/).
- [LlamaIndex for Agents](./llamaindex_agents.md) - LlamaIndex enables building intelligent, semi-autonomous agents, more information can be found [here](https://www.llamaindex.ai/).

File: docs/howtos/integrations/llamaindex_agents.md
After:
# Evaluating LlamaIndex Agents

Building agents that can intelligently use tools and make decisions is only half the journey; ensuring that these agents are accurate, reliable, and performant is what truly defines their success. [LlamaIndex](https://docs.llamaindex.ai/en/stable/understanding/agent/) provides various ways to create agents including [FunctionAgents](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/), [CodeActAgents](https://docs.llamaindex.ai/en/stable/examples/agent/code_act_agent/), and [ReActAgents](https://docs.llamaindex.ai/en/stable/examples/agent/react_agent/). In this tutorial, we will explore how to evaluate these different agent types using both pre-built Ragas metrics and custom evaluation metrics.

Let's get started.

The tutorial is divided into three comprehensive sections:

1. **Evaluating with Off-the-Shelf Raga...[truncated]
--- Similar PR #1974 ---
File: docs/howtos/integrations/aws_bedrock.md
After:

# Create and Evaluate an Agent Integrated with Bedrock Knowledge Bases and Attached Action Group

In this notebook, you will learn how to evaluate an Amazon Bedrock Agent. The agent we'll evaluate is a restaurant agent whose tasks include providing clients with information about adult and children's menus and managing the table booking system. This agent is inspired by a [features example notebooks](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/agents-and-function-calling/bedrock-agents/features-examples/05-create-agent-with-knowledge-base-and-action-group) of [Amazon Bedrock Agents](https://aws.amazon.com/bedrock/agents/) with minor changes. You can learn more about the agent creation process [here](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/agents-and-function-calling/bedrock-agents/features-examples/05-create-agent-with-knowledge-base-and-action-group).

The architecture is illustrated below:

![architecture image](../../_static/architecture.png)

The steps covered in this notebook include:

- Importing necessary libraries
- Creating the agent
- Defining the Ragas metrics
- Evaluating the agent
- Cleaning up the created resources

??? note "Click to View the Agent creation"
    ## Import the needed libraries

    First step is to install the pre-requisites packages


    ```python
    %pip install --upgrade -q boto3 opensearch-py botocore awscli retrying ragas
    ```


    ```python
    import os
    import time
    import boto3
    import logging
    import pprint
    import json

    from knowledge_base import BedrockKnowledgeBase
    from agent import (
        create_agent_role_and_policies,
        create_lambda_role,
        delete_agent_roles_and_policies,
        create_dynamodb,
        create_lambda,
        clean_up_resources,
    )
    ```


    ```python
    # Clients
    s3_client = boto3.client("s3")
    sts_client = boto3.client("sts")
    session = boto3...[truncated]
--- Similar PR #2011 ---
File: docs/howtos/integrations/index.md
Before:
- [Haystack](./haystack.md) - Haystack is a LLM orchestration framework to build customizable, production-ready LLM applications, more information can be found [here](https://haystack.deepset.ai/).
After:
- [Haystack](./haystack.md) - Haystack is a LLM orchestration framework to build customizable, production-ready LLM applications, more information can be found [here](https://haystack.deepset.ai/).
- [LlamaStack](./llama_stack.md) â€“ A unified framework by Meta for building and deploying generative AI apps across local, cloud, and mobile; [docs](https://llama-stack.readthedocs.io/en/latest/)

File: docs/howtos/integrations/llama_stack.md
After:
# Evaluating LlamaStack Web Search Groundedness with Llama 4

In this tutorial we will measure the groundedness of response generated by the LlamaStack's web search agent. [LlamaStack](https://llama-stack.readthedocs.io/en/latest/) is an open-source framework maintained by meta, that streamlines the development and deployment of large language model-powered applications. The evaluations will be done using the Ragas metrics and using Meta Llama 4 Maverick as the judge.

## Setup and Running a LlamaStack server

This command installs all the dependencies needed for the LlamaStack server with the together inference provider

Use the command with conda
```shell
!pip install ragas langchain-together uv 
!uv run --with llama-stack llama stack build --template together --image-type conda
```

Use the command with venv
```shell
!pip install ragas langchain-together uv 
!uv run --with llama-stack llama stack build --template together --image-type venv
```


```python
import os
import subprocess


def run_llama_stack_server_background():
    log_file = open("llama_stack_server.log", "w")
    process = subprocess.Popen(
        "uv run --with llama-stack llama stack run together --image-type venv",
        shell=True,
        stdout=log_file,
        stderr=log_file,
        text=True,
   ...[truncated]